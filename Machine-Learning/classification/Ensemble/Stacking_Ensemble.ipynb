{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 스태킹 앙상블(Stacking Ensemble)\n",
    "- 여러 알고리즘을 결합해 예측 결과를 도출 => 배깅, 부스팅과 비슷\n",
    "- 개별 알고리즘으로 예측한 데이터를 기반으로 다시 예측을 수행한다는 점이 차이점\n",
    "- 두 종류의 모델 필요\n",
    "    - 개별적인 학습 모델\n",
    "    - 학습 데이터로 학습하는 모델"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score of KNN:  0.9385964912280702\nScore of Random Forest:  0.9824561403508771\nScore of Decision Tree:  0.9736842105263158\nScore of AdaBoostClassifier:  0.9824561403508771\nScore of Logistic Regression:  0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "dt = DecisionTreeClassifier()\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "lr = LogisticRegression(C=10)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "dt.fit(X_train, y_train)\n",
    "ada.fit(X_train, y_train)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "knn_pred = knn.predict(X_test)\n",
    "rf_pred = rf.predict(X_test)\n",
    "dt_pred = dt.predict(X_test)\n",
    "ada_pred = ada.predict(X_test)\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "print('Score of KNN: ', accuracy_score(y_test, knn_pred))\n",
    "print('Score of Random Forest: ', accuracy_score(y_test, rf_pred))\n",
    "print('Score of Decision Tree: ', accuracy_score(y_test, dt_pred))\n",
    "print('Score of AdaBoostClassifier: ', accuracy_score(y_test, ada_pred))\n",
    "print('Score of Logistic Regression: ', accuracy_score(y_test, lr_pred))"
   ]
  },
  {
   "source": [
    "## KNN, Random Forest, Decision Tree, AdaboostClassifer를 개별적인 학습 모델로 사용"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4, 114)\n(114, 4)\n"
     ]
    }
   ],
   "source": [
    "pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
    "print(pred.shape)\n",
    "\n",
    "pred = np.transpose(pred)\n",
    "print(pred.shape)"
   ]
  },
  {
   "source": [
    " ## Losgistic Regression을 개별 모델의 예측 데이터를 학습 데이터로 학습하는 모델로 사용"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score of Stacking Ensemble:  0.9912280701754386\n"
     ]
    }
   ],
   "source": [
    "lr.fit(pred, y_test)\n",
    "pred_final = lr.predict(pred)\n",
    "print('Score of Stacking Ensemble: ', accuracy_score(y_test, pred_final))"
   ]
  },
  {
   "source": [
    "### 이처럼 스태킹 앙상블은 높은 정확도를 보인다"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Cross Validation set 기반 스태킹\n",
    "- 과적합(overfitting)을 개선하기 위해 교차 검증 기반으로 예측된 결과 데이터 세트를 이용"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(455, 30) (114, 30)\n(455, 4) (114, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def get_stacking_base_datasets(model, X_train, y_train, X_test, n_folds):\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False)\n",
    "    train_pred = np.zeros((X_train.shape[0], 1))\n",
    "    test_pred = np.zeros((X_test.shape[0], n_folds))\n",
    "\n",
    "    for folder_index, (train_index, valid_index) in enumerate(kf.split(X_train)):\n",
    "        X_tr = X_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        X_te = X_train[valid_index]\n",
    "        model.fit(X_tr, y_tr)\n",
    "        train_pred[valid_index, :] = model.predict(X_te).reshape(-1, 1)\n",
    "        test_pred[:, folder_index] = model.predict(X_test)\n",
    "\n",
    "    test_mean = np.mean(test_pred, axis=1).reshape(-1, 1)\n",
    "    return train_pred, test_mean\n",
    "\n",
    "knn_train, knn_test = get_stacking_base_datasets(knn, X_train, y_train, X_test, 7)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf, X_train, y_train, X_test, 7)\n",
    "dt_train, dt_test = get_stacking_base_datasets(dt, X_train, y_train, X_test, 7)\n",
    "ada_train, ada_test = get_stacking_base_datasets(ada, X_train, y_train, X_test, 7)\n",
    "\n",
    "X_train_final = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis=1)\n",
    "X_test_final = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis=1)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(X_train_final.shape, X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score of Stacking Ensemble(Based on CVset):  0.9912280701754386\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train_final, y_train)\n",
    "pred_final = lr.predict(X_test_final)\n",
    "print('Score of Stacking Ensemble(Based on CVset): ', accuracy_score(y_test, pred_final))"
   ]
  }
 ]
}